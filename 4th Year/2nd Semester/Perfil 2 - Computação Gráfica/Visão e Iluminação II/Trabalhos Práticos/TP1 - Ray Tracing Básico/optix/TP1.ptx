//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-25769353
// Cuda compilation tools, release 10.1, V10.1.105
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_30
.address_size 64

	// .globl	__closesthit__radiance
.const .align 8 .b8 optixLaunchParams[88];

.visible .entry __closesthit__radiance(

)
{
	.local .align 4 .b8 	__local_depot0[12];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<6>;
	.reg .f32 	%f<136>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<37>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd3, %SPL, 0;
	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd11, %r1;
	shl.b64 	%rd12, %rd11, 32;
	cvt.u64.u32	%rd13, %r2;
	or.b64  	%rd1, %rd12, %rd13;
	// inline asm
	call (%rd8), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	mov.u64 	%rd14, 1065353216;
	st.local.u32 	[%rd3+4], %rd14;
	st.local.u32 	[%rd3], %rd14;
	mov.u32 	%r13, 1065353216;
	st.local.u32 	[%rd3+8], %r13;
	shr.u64 	%rd15, %rd10, 32;
	cvt.u32.u64	%r11, %rd15;
	cvt.u32.u64	%r12, %rd10;
	// inline asm
	call (%r3), _optix_read_primitive_idx, ();
	// inline asm
	ld.u64 	%rd16, [%rd8];
	mul.wide.s32 	%rd17, %r3, 12;
	add.s64 	%rd18, %rd16, %rd17;
	ld.u32 	%r14, [%rd18];
	ld.u32 	%r15, [%rd18+4];
	ld.u32 	%r16, [%rd18+8];
	// inline asm
	call (%f19, %f20), _optix_get_triangle_barycentrics, ();
	// inline asm
	mov.f32 	%f30, 0f3F800000;
	sub.ftz.f32 	%f31, %f30, %f19;
	sub.ftz.f32 	%f32, %f31, %f20;
	cvt.u64.u32	%rd4, %r14;
	ld.u64 	%rd19, [%rd8+8];
	mul.wide.u32 	%rd20, %r14, 16;
	add.s64 	%rd21, %rd19, %rd20;
	ld.v4.f32 	{%f33, %f34, %f35, %f36}, [%rd21];
	mov.u32 	%r10, 1;
	mov.u32 	%r9, 2;
	cvt.u64.u32	%rd5, %r15;
	mul.wide.u32 	%rd22, %r15, 16;
	add.s64 	%rd23, %rd19, %rd22;
	ld.v4.f32 	{%f40, %f41, %f42, %f43}, [%rd23];
	mul.ftz.f32 	%f47, %f19, %f40;
	mul.ftz.f32 	%f48, %f19, %f41;
	mul.ftz.f32 	%f49, %f19, %f42;
	fma.rn.ftz.f32 	%f50, %f33, %f32, %f47;
	fma.rn.ftz.f32 	%f51, %f34, %f32, %f48;
	fma.rn.ftz.f32 	%f52, %f32, %f35, %f49;
	cvt.u64.u32	%rd6, %r16;
	mul.wide.u32 	%rd24, %r16, 16;
	add.s64 	%rd25, %rd19, %rd24;
	ld.v4.f32 	{%f53, %f54, %f55, %f56}, [%rd25];
	fma.rn.ftz.f32 	%f21, %f20, %f53, %f50;
	fma.rn.ftz.f32 	%f22, %f20, %f54, %f51;
	fma.rn.ftz.f32 	%f23, %f20, %f55, %f52;
	ld.u64 	%rd26, [%rd8+16];
	add.s64 	%rd27, %rd26, %rd20;
	ld.v4.f32 	{%f60, %f61, %f62, %f63}, [%rd27];
	add.s64 	%rd28, %rd26, %rd22;
	ld.v4.f32 	{%f67, %f68, %f69, %f70}, [%rd28];
	mul.ftz.f32 	%f74, %f19, %f67;
	mul.ftz.f32 	%f75, %f19, %f68;
	mul.ftz.f32 	%f76, %f19, %f69;
	fma.rn.ftz.f32 	%f77, %f32, %f60, %f74;
	fma.rn.ftz.f32 	%f78, %f32, %f61, %f75;
	fma.rn.ftz.f32 	%f79, %f32, %f62, %f76;
	add.s64 	%rd29, %rd26, %rd24;
	ld.v4.f32 	{%f80, %f81, %f82, %f83}, [%rd29];
	fma.rn.ftz.f32 	%f87, %f20, %f80, %f77;
	fma.rn.ftz.f32 	%f88, %f20, %f81, %f78;
	fma.rn.ftz.f32 	%f89, %f20, %f82, %f79;
	mul.ftz.f32 	%f90, %f88, %f88;
	fma.rn.ftz.f32 	%f91, %f87, %f87, %f90;
	fma.rn.ftz.f32 	%f92, %f89, %f89, %f91;
	rsqrt.approx.ftz.f32 	%f93, %f92;
	mul.ftz.f32 	%f94, %f87, %f93;
	mul.ftz.f32 	%f95, %f88, %f93;
	mul.ftz.f32 	%f96, %f89, %f93;
	mov.f32 	%f97, 0f3F8147AE;
	rsqrt.approx.ftz.f32 	%f98, %f97;
	mul.ftz.f32 	%f99, %f98, 0fBF19999A;
	mul.ftz.f32 	%f100, %f98, 0f3ECCCCCD;
	mul.ftz.f32 	%f101, %f98, 0fBF333333;
	mul.ftz.f32 	%f102, %f95, %f100;
	fma.rn.ftz.f32 	%f103, %f94, %f99, %f102;
	fma.rn.ftz.f32 	%f3, %f96, %f101, %f103;
	ld.const.u64 	%rd9, [optixLaunchParams+72];
	mov.u32 	%r6, 255;
	mov.u32 	%r7, 4;
	mov.f32 	%f24, 0fBF19999A;
	mov.f32 	%f25, 0f3ECCCCCD;
	mov.f32 	%f26, 0fBF333333;
	mov.f32 	%f27, 0f3DCCCCCD;
	mov.f32 	%f28, 0f60AD78EC;
	mov.f32 	%f29, 0f00000000;
	// inline asm
	call (%r4, %r5), _optix_trace_2, (%rd9, %f21, %f22, %f23, %f24, %f25, %f26, %f27, %f28, %f29, %r6, %r7, %r10, %r9, %r10, %r11, %r12);
	// inline asm
	ld.u32 	%r17, [%rd8+48];
	setp.eq.s32	%p1, %r17, 0;
	@%p1 bra 	BB0_3;

	ld.u64 	%rd7, [%rd8+24];
	setp.eq.s64	%p2, %rd7, 0;
	@%p2 bra 	BB0_3;

	shl.b64 	%rd30, %rd4, 4;
	add.s64 	%rd31, %rd7, %rd30;
	ld.v2.f32 	{%f104, %f105}, [%rd31];
	shl.b64 	%rd32, %rd5, 4;
	add.s64 	%rd33, %rd7, %rd32;
	ld.v2.f32 	{%f111, %f112}, [%rd33];
	mul.ftz.f32 	%f115, %f19, %f111;
	mul.ftz.f32 	%f116, %f19, %f112;
	fma.rn.ftz.f32 	%f117, %f32, %f104, %f115;
	fma.rn.ftz.f32 	%f118, %f32, %f105, %f116;
	shl.b64 	%rd34, %rd6, 4;
	add.s64 	%rd35, %rd7, %rd34;
	ld.v2.f32 	{%f119, %f120}, [%rd35];
	fma.rn.ftz.f32 	%f123, %f20, %f119, %f117;
	fma.rn.ftz.f32 	%f124, %f20, %f120, %f118;
	ld.u64 	%rd36, [%rd8+56];
	tex.2d.v4.f32.f32	{%f135, %f134, %f132, %f125}, [%rd36, {%f123, %f124}];
	cvt.ftz.f64.f32	%fd1, %f3;
	setp.gt.f64	%p3, %fd1, 0d3FE999999999999A;
	selp.f32	%f133, %f3, 0f3ECCCCCD, %p3;
	bra.uni 	BB0_4;

BB0_3:
	cvt.ftz.f64.f32	%fd2, %f3;
	setp.gt.f64	%p4, %fd2, 0d3FD3333333333333;
	ld.v2.f32 	{%f135, %f134}, [%rd8+64];
	ld.f32 	%f132, [%rd8+72];
	selp.f32	%f133, %f3, 0f3E99999A, %p4;

BB0_4:
	mul.ftz.f32 	%f16, %f133, %f135;
	st.f32 	[%rd1], %f16;
	mul.ftz.f32 	%f17, %f133, %f134;
	st.f32 	[%rd1+4], %f17;
	mul.ftz.f32 	%f18, %f132, %f133;
	st.f32 	[%rd1+8], %f18;
	ld.local.f32 	%f128, [%rd3+4];
	setp.neu.ftz.f32	%p5, %f128, 0f3F800000;
	@%p5 bra 	BB0_6;

	mul.ftz.f32 	%f129, %f16, 0f3F000000;
	st.f32 	[%rd1], %f129;
	mul.ftz.f32 	%f130, %f17, 0f3F000000;
	st.f32 	[%rd1+4], %f130;
	mul.ftz.f32 	%f131, %f18, 0f3F000000;
	st.f32 	[%rd1+8], %f131;

BB0_6:
	ret;
}

	// .globl	__anyhit__radiance
.visible .entry __anyhit__radiance(

)
{



	ret;
}

	// .globl	__miss__radiance
.visible .entry __miss__radiance(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<6>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 1065353216;
	st.u32 	[%rd4+4], %rd5;
	st.u32 	[%rd4], %rd5;
	mov.u32 	%r3, 1065353216;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__closesthit__shadow
.visible .entry __closesthit__shadow(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 1065353216;
	st.u32 	[%rd4+4], %rd5;
	mov.u64 	%rd6, 0;
	st.u32 	[%rd4], %rd6;
	mov.u32 	%r3, 0;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__anyhit__shadow
.visible .entry __anyhit__shadow(

)
{



	ret;
}

	// .globl	__miss__shadow
.visible .entry __miss__shadow(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 0;
	st.u32 	[%rd4+4], %rd5;
	mov.u64 	%rd6, 1065353216;
	st.u32 	[%rd4], %rd6;
	mov.u32 	%r3, 0;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__closesthit__phong_alphaTrans
.visible .entry __closesthit__phong_alphaTrans(

)
{



	ret;
}

	// .globl	__anyhit__phong_alphaTrans
.visible .entry __anyhit__phong_alphaTrans(

)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<84>;
	.reg .b32 	%r<8>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<29>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd9, %r1;
	shl.b64 	%rd10, %rd9, 32;
	cvt.u64.u32	%rd11, %r2;
	or.b64  	%rd1, %rd10, %rd11;
	// inline asm
	call (%rd8), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	// inline asm
	call (%r3), _optix_read_primitive_idx, ();
	// inline asm
	ld.u64 	%rd12, [%rd8];
	mul.wide.s32 	%rd13, %r3, 12;
	add.s64 	%rd14, %rd12, %rd13;
	ld.u32 	%r4, [%rd14];
	ld.u32 	%r5, [%rd14+4];
	ld.u32 	%r6, [%rd14+8];
	// inline asm
	call (%f12, %f13), _optix_get_triangle_barycentrics, ();
	// inline asm
	mov.f32 	%f14, 0f3F800000;
	sub.ftz.f32 	%f15, %f14, %f12;
	sub.ftz.f32 	%f3, %f15, %f13;
	cvt.u64.u32	%rd3, %r4;
	ld.u64 	%rd15, [%rd8+16];
	mul.wide.u32 	%rd16, %r4, 16;
	add.s64 	%rd17, %rd15, %rd16;
	ld.v4.f32 	{%f16, %f17, %f18, %f19}, [%rd17];
	cvt.u64.u32	%rd4, %r5;
	mul.wide.u32 	%rd18, %r5, 16;
	add.s64 	%rd19, %rd15, %rd18;
	ld.v4.f32 	{%f23, %f24, %f25, %f26}, [%rd19];
	mul.ftz.f32 	%f30, %f12, %f23;
	mul.ftz.f32 	%f31, %f12, %f24;
	mul.ftz.f32 	%f32, %f12, %f25;
	fma.rn.ftz.f32 	%f33, %f16, %f3, %f30;
	fma.rn.ftz.f32 	%f34, %f17, %f3, %f31;
	fma.rn.ftz.f32 	%f35, %f18, %f3, %f32;
	cvt.u64.u32	%rd5, %r6;
	mul.wide.u32 	%rd20, %r6, 16;
	add.s64 	%rd21, %rd15, %rd20;
	ld.v4.f32 	{%f36, %f37, %f38, %f39}, [%rd21];
	fma.rn.ftz.f32 	%f43, %f13, %f36, %f33;
	fma.rn.ftz.f32 	%f44, %f13, %f37, %f34;
	fma.rn.ftz.f32 	%f45, %f13, %f38, %f35;
	mul.ftz.f32 	%f46, %f44, %f44;
	fma.rn.ftz.f32 	%f47, %f43, %f43, %f46;
	fma.rn.ftz.f32 	%f48, %f45, %f45, %f47;
	rsqrt.approx.ftz.f32 	%f49, %f48;
	mul.ftz.f32 	%f50, %f43, %f49;
	mul.ftz.f32 	%f51, %f44, %f49;
	mul.ftz.f32 	%f52, %f45, %f49;
	mov.f32 	%f53, 0f3F8147AE;
	rsqrt.approx.ftz.f32 	%f54, %f53;
	mul.ftz.f32 	%f55, %f54, 0fBF19999A;
	mul.ftz.f32 	%f56, %f54, 0f3ECCCCCD;
	mul.ftz.f32 	%f57, %f54, 0fBF333333;
	mul.ftz.f32 	%f58, %f51, %f56;
	fma.rn.ftz.f32 	%f59, %f50, %f55, %f58;
	fma.rn.ftz.f32 	%f4, %f52, %f57, %f59;
	ld.u32 	%r7, [%rd8+48];
	setp.eq.s32	%p1, %r7, 0;
	@%p1 bra 	BB7_7;

	ld.u64 	%rd6, [%rd8+24];
	setp.eq.s64	%p2, %rd6, 0;
	@%p2 bra 	BB7_7;

	shl.b64 	%rd22, %rd3, 4;
	add.s64 	%rd23, %rd6, %rd22;
	ld.v2.f32 	{%f60, %f61}, [%rd23];
	shl.b64 	%rd24, %rd4, 4;
	add.s64 	%rd25, %rd6, %rd24;
	ld.v2.f32 	{%f64, %f65}, [%rd25];
	mul.ftz.f32 	%f68, %f12, %f64;
	mul.ftz.f32 	%f69, %f12, %f65;
	fma.rn.ftz.f32 	%f70, %f3, %f60, %f68;
	fma.rn.ftz.f32 	%f71, %f3, %f61, %f69;
	shl.b64 	%rd26, %rd5, 4;
	add.s64 	%rd27, %rd6, %rd26;
	ld.v2.f32 	{%f72, %f73}, [%rd27];
	fma.rn.ftz.f32 	%f76, %f13, %f72, %f70;
	fma.rn.ftz.f32 	%f77, %f13, %f73, %f71;
	ld.u64 	%rd28, [%rd8+56];
	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [%rd28, {%f76, %f77}];
	setp.eq.ftz.f32	%p3, %f8, 0f3F800000;
	@%p3 bra 	BB7_4;
	bra.uni 	BB7_3;

BB7_4:
	cvt.ftz.f64.f32	%fd1, %f4;
	setp.gt.f64	%p4, %fd1, 0d3FD3333333333333;
	@%p4 bra 	BB7_6;
	bra.uni 	BB7_5;

BB7_6:
	mul.ftz.f32 	%f81, %f4, %f5;
	st.f32 	[%rd1], %f81;
	mul.ftz.f32 	%f82, %f4, %f6;
	st.f32 	[%rd1+4], %f82;
	mul.ftz.f32 	%f83, %f4, %f7;
	st.f32 	[%rd1+8], %f83;
	bra.uni 	BB7_7;

BB7_3:
	// inline asm
	call _optix_ignore_intersection, ();
	// inline asm
	bra.uni 	BB7_7;

BB7_5:
	mul.ftz.f32 	%f78, %f5, 0f3E99999A;
	st.f32 	[%rd1], %f78;
	mul.ftz.f32 	%f79, %f6, 0f3E99999A;
	st.f32 	[%rd1+4], %f79;
	mul.ftz.f32 	%f80, %f7, 0f3E99999A;
	st.f32 	[%rd1+8], %f80;

BB7_7:
	ret;
}

	// .globl	__miss__phong_alphaTrans
.visible .entry __miss__phong_alphaTrans(

)
{



	ret;
}

	// .globl	__closesthit__shadow_alphaTrans
.visible .entry __closesthit__shadow_alphaTrans(

)
{



	ret;
}

	// .globl	__anyhit__shadow_alphaTrans
.visible .entry __anyhit__shadow_alphaTrans(

)
{
	.reg .pred 	%p<4>;
	.reg .f32 	%f<30>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<14>;


	// inline asm
	call (%rd4), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	// inline asm
	call (%r1), _optix_read_primitive_idx, ();
	// inline asm
	ld.u64 	%rd5, [%rd4];
	mul.wide.s32 	%rd6, %r1, 12;
	add.s64 	%rd2, %rd5, %rd6;
	// inline asm
	call (%f3, %f4), _optix_get_triangle_barycentrics, ();
	// inline asm
	ld.u32 	%r2, [%rd4+48];
	setp.eq.s32	%p1, %r2, 0;
	@%p1 bra 	BB10_4;

	ld.u64 	%rd3, [%rd4+24];
	setp.eq.s64	%p2, %rd3, 0;
	@%p2 bra 	BB10_4;

	ld.u32 	%r3, [%rd2];
	ld.u32 	%r4, [%rd2+4];
	ld.u32 	%r5, [%rd2+8];
	mov.f32 	%f5, 0f3F800000;
	sub.ftz.f32 	%f6, %f5, %f3;
	sub.ftz.f32 	%f7, %f6, %f4;
	mul.wide.u32 	%rd7, %r3, 16;
	add.s64 	%rd8, %rd3, %rd7;
	ld.v2.f32 	{%f8, %f9}, [%rd8];
	mul.wide.u32 	%rd9, %r4, 16;
	add.s64 	%rd10, %rd3, %rd9;
	ld.v2.f32 	{%f12, %f13}, [%rd10];
	mul.ftz.f32 	%f16, %f3, %f12;
	mul.ftz.f32 	%f17, %f3, %f13;
	fma.rn.ftz.f32 	%f18, %f7, %f8, %f16;
	fma.rn.ftz.f32 	%f19, %f7, %f9, %f17;
	mul.wide.u32 	%rd11, %r5, 16;
	add.s64 	%rd12, %rd3, %rd11;
	ld.v2.f32 	{%f20, %f21}, [%rd12];
	fma.rn.ftz.f32 	%f24, %f4, %f20, %f18;
	fma.rn.ftz.f32 	%f25, %f4, %f21, %f19;
	ld.u64 	%rd13, [%rd4+56];
	tex.2d.v4.f32.f32	{%f26, %f27, %f28, %f29}, [%rd13, {%f24, %f25}];
	setp.eq.ftz.f32	%p3, %f29, 0f3F800000;
	@%p3 bra 	BB10_4;

	// inline asm
	call _optix_ignore_intersection, ();
	// inline asm

BB10_4:
	ret;
}

	// .globl	__miss__shadow_alphaTrans
.visible .entry __miss__shadow_alphaTrans(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 0;
	st.u32 	[%rd4+4], %rd5;
	mov.u64 	%rd6, 1065353216;
	st.u32 	[%rd4], %rd6;
	mov.u32 	%r3, 0;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__anyhit__phong_glass
.visible .entry __anyhit__phong_glass(

)
{



	ret;
}

	// .globl	__closesthit__phong_glass
.visible .entry __closesthit__phong_glass(

)
{
	.local .align 4 .b8 	__local_depot13[24];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<164>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<30>;


	mov.u64 	%SPL, __local_depot13;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd4, %SP, 0;
	add.u64 	%rd5, %SPL, 0;
	add.u64 	%rd6, %SP, 12;
	add.u64 	%rd7, %SPL, 12;
	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd8, %r1;
	shl.b64 	%rd9, %rd8, 32;
	cvt.u64.u32	%rd10, %r2;
	or.b64  	%rd11, %rd9, %rd10;
	// inline asm
	call (%rd1), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	// inline asm
	call (%r3), _optix_read_primitive_idx, ();
	// inline asm
	ld.u64 	%rd12, [%rd1];
	mul.wide.s32 	%rd13, %r3, 12;
	add.s64 	%rd14, %rd12, %rd13;
	ld.u32 	%r28, [%rd14];
	ld.u32 	%r29, [%rd14+4];
	ld.u32 	%r30, [%rd14+8];
	// inline asm
	call (%f1, %f2), _optix_get_triangle_barycentrics, ();
	// inline asm
	mov.f32 	%f21, 0f3F800000;
	sub.ftz.f32 	%f22, %f21, %f1;
	sub.ftz.f32 	%f23, %f22, %f2;
	ld.u64 	%rd15, [%rd1+8];
	mul.wide.u32 	%rd16, %r28, 16;
	add.s64 	%rd17, %rd15, %rd16;
	ld.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd17];
	mov.u32 	%r25, 0;
	mov.u32 	%r24, 2;
	mul.wide.u32 	%rd18, %r29, 16;
	add.s64 	%rd19, %rd15, %rd18;
	ld.v4.f32 	{%f31, %f32, %f33, %f34}, [%rd19];
	mul.ftz.f32 	%f38, %f1, %f31;
	mul.ftz.f32 	%f39, %f1, %f32;
	mul.ftz.f32 	%f40, %f1, %f33;
	fma.rn.ftz.f32 	%f41, %f24, %f23, %f38;
	fma.rn.ftz.f32 	%f42, %f25, %f23, %f39;
	fma.rn.ftz.f32 	%f43, %f26, %f23, %f40;
	mul.wide.u32 	%rd20, %r30, 16;
	add.s64 	%rd21, %rd15, %rd20;
	ld.v4.f32 	{%f44, %f45, %f46, %f47}, [%rd21];
	fma.rn.ftz.f32 	%f3, %f2, %f44, %f41;
	fma.rn.ftz.f32 	%f4, %f2, %f45, %f42;
	fma.rn.ftz.f32 	%f5, %f2, %f46, %f43;
	ld.u64 	%rd22, [%rd1+16];
	add.s64 	%rd23, %rd22, %rd16;
	ld.v4.f32 	{%f51, %f52, %f53, %f54}, [%rd23];
	add.s64 	%rd24, %rd22, %rd18;
	ld.v4.f32 	{%f58, %f59, %f60, %f61}, [%rd24];
	mul.ftz.f32 	%f65, %f1, %f58;
	mul.ftz.f32 	%f66, %f1, %f59;
	mul.ftz.f32 	%f67, %f1, %f60;
	fma.rn.ftz.f32 	%f68, %f23, %f51, %f65;
	fma.rn.ftz.f32 	%f69, %f23, %f52, %f66;
	fma.rn.ftz.f32 	%f70, %f23, %f53, %f67;
	add.s64 	%rd25, %rd22, %rd20;
	ld.v4.f32 	{%f71, %f72, %f73, %f74}, [%rd25];
	fma.rn.ftz.f32 	%f78, %f2, %f71, %f68;
	fma.rn.ftz.f32 	%f79, %f2, %f72, %f69;
	fma.rn.ftz.f32 	%f80, %f2, %f73, %f70;
	// inline asm
	call (%r4), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r5), _optix_get_launch_index_y, ();
	// inline asm
	cvt.rn.f32.s32	%f81, %r4;
	add.ftz.f32 	%f82, %f81, 0f3F000000;
	cvt.rn.f32.s32	%f83, %r5;
	add.ftz.f32 	%f84, %f83, 0f3F000000;
	// inline asm
	call (%r7), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r8), _optix_get_launch_dimension_y, ();
	// inline asm
	cvt.rn.f32.u32	%f85, %r7;
	cvt.rn.f32.u32	%f86, %r8;
	div.approx.ftz.f32 	%f87, %f82, %f85;
	div.approx.ftz.f32 	%f88, %f84, %f86;
	fma.rn.ftz.f32 	%f89, %f87, 0f40000000, 0fBF800000;
	fma.rn.ftz.f32 	%f90, %f88, 0f40000000, 0fBF800000;
	ld.const.v2.f32 	{%f91, %f92}, [optixLaunchParams+48];
	ld.const.v2.f32 	{%f95, %f96}, [optixLaunchParams+56];
	ld.const.f32 	%f99, [optixLaunchParams+36];
	fma.rn.ftz.f32 	%f100, %f91, %f89, %f99;
	ld.const.v2.f32 	{%f101, %f102}, [optixLaunchParams+40];
	fma.rn.ftz.f32 	%f105, %f89, %f92, %f101;
	fma.rn.ftz.f32 	%f106, %f89, %f95, %f102;
	ld.const.v2.f32 	{%f107, %f108}, [optixLaunchParams+64];
	fma.rn.ftz.f32 	%f111, %f90, %f96, %f100;
	fma.rn.ftz.f32 	%f112, %f90, %f107, %f105;
	fma.rn.ftz.f32 	%f113, %f90, %f108, %f106;
	mul.ftz.f32 	%f114, %f112, %f112;
	fma.rn.ftz.f32 	%f115, %f111, %f111, %f114;
	fma.rn.ftz.f32 	%f116, %f113, %f113, %f115;
	rsqrt.approx.ftz.f32 	%f117, %f116;
	mul.ftz.f32 	%f15, %f111, %f117;
	mul.ftz.f32 	%f16, %f112, %f117;
	mul.ftz.f32 	%f17, %f113, %f117;
	mov.u64 	%rd26, 0;
	st.local.u32 	[%rd5+4], %rd26;
	st.local.u32 	[%rd5], %rd26;
	st.local.u32 	[%rd5+8], %r25;
	shr.u64 	%rd27, %rd4, 32;
	cvt.u32.u64	%r17, %rd27;
	cvt.u32.u64	%r18, %rd4;
	add.ftz.f32 	%f118, %f78, %f78;
	add.ftz.f32 	%f119, %f79, %f79;
	add.ftz.f32 	%f120, %f80, %f80;
	mul.ftz.f32 	%f121, %f79, %f16;
	fma.rn.ftz.f32 	%f122, %f78, %f15, %f121;
	fma.rn.ftz.f32 	%f123, %f80, %f17, %f122;
	mul.ftz.f32 	%f124, %f118, %f123;
	mul.ftz.f32 	%f125, %f119, %f123;
	mul.ftz.f32 	%f126, %f120, %f123;
	sub.ftz.f32 	%f6, %f15, %f124;
	sub.ftz.f32 	%f7, %f16, %f125;
	sub.ftz.f32 	%f8, %f17, %f126;
	ld.const.u64 	%rd2, [optixLaunchParams+72];
	mov.u32 	%r21, 255;
	mov.f32 	%f18, 0f3727C5AC;
	mov.f32 	%f19, 0f60AD78EC;
	mov.f32 	%f20, 0f00000000;
	// inline asm
	call (%r10, %r11), _optix_trace_2, (%rd2, %f3, %f4, %f5, %f6, %f7, %f8, %f18, %f19, %f20, %r21, %r25, %r25, %r24, %r25, %r17, %r18);
	// inline asm
	mov.u64 	%rd28, 1065353216;
	st.local.u32 	[%rd7+4], %rd28;
	st.local.u32 	[%rd7], %rd28;
	mov.u32 	%r31, 1065353216;
	st.local.u32 	[%rd7+8], %r31;
	shr.u64 	%rd29, %rd6, 32;
	cvt.u32.u64	%r26, %rd29;
	cvt.u32.u64	%r27, %rd6;
	// inline asm
	call (%r19, %r20), _optix_trace_2, (%rd2, %f3, %f4, %f5, %f15, %f16, %f17, %f18, %f19, %f20, %r21, %r25, %r25, %r24, %r25, %r26, %r27);
	// inline asm
	mul.ftz.f32 	%f127, %f79, %f79;
	fma.rn.ftz.f32 	%f128, %f78, %f78, %f127;
	fma.rn.ftz.f32 	%f129, %f80, %f80, %f128;
	rsqrt.approx.ftz.f32 	%f130, %f129;
	mul.ftz.f32 	%f131, %f78, %f130;
	mul.ftz.f32 	%f132, %f79, %f130;
	mul.ftz.f32 	%f133, %f80, %f130;
	mul.ftz.f32 	%f134, %f16, %f16;
	fma.rn.ftz.f32 	%f135, %f15, %f15, %f134;
	fma.rn.ftz.f32 	%f136, %f17, %f17, %f135;
	rsqrt.approx.ftz.f32 	%f137, %f136;
	mul.ftz.f32 	%f138, %f15, %f137;
	mul.ftz.f32 	%f139, %f16, %f137;
	mul.ftz.f32 	%f140, %f17, %f137;
	mul.ftz.f32 	%f141, %f132, %f139;
	fma.rn.ftz.f32 	%f142, %f131, %f138, %f141;
	fma.rn.ftz.f32 	%f143, %f133, %f140, %f142;
	cvt.ftz.f64.f32	%fd1, %f143;
	abs.f64 	%fd2, %fd1;
	cvt.rn.ftz.f32.f64	%f144, %fd2;
	sub.ftz.f32 	%f145, %f21, %f144;
	lg2.approx.ftz.f32 	%f146, %f145;
	mul.ftz.f32 	%f147, %f146, 0f40A00000;
	ex2.approx.ftz.f32 	%f148, %f147;
	sub.ftz.f32 	%f149, %f21, 0f3D23D70A;
	fma.rn.ftz.f32 	%f150, %f148, %f149, 0f3D23D70A;
	sub.ftz.f32 	%f151, %f21, %f150;
	ld.local.f32 	%f152, [%rd7];
	ld.local.f32 	%f153, [%rd7+4];
	ld.local.f32 	%f154, [%rd7+8];
	ld.local.f32 	%f155, [%rd5];
	mul.ftz.f32 	%f156, %f150, %f155;
	ld.local.f32 	%f157, [%rd5+4];
	mul.ftz.f32 	%f158, %f150, %f157;
	ld.local.f32 	%f159, [%rd5+8];
	mul.ftz.f32 	%f160, %f150, %f159;
	fma.rn.ftz.f32 	%f161, %f152, %f151, %f156;
	fma.rn.ftz.f32 	%f162, %f153, %f151, %f158;
	fma.rn.ftz.f32 	%f163, %f154, %f151, %f160;
	st.f32 	[%rd11], %f161;
	st.f32 	[%rd11+4], %f162;
	st.f32 	[%rd11+8], %f163;
	ret;
}

	// .globl	__miss__phong_glass
.visible .entry __miss__phong_glass(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<6>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 1065353216;
	st.u32 	[%rd4+4], %rd5;
	st.u32 	[%rd4], %rd5;
	mov.u32 	%r3, 1065353216;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__anyhit__shadow_glass
.visible .entry __anyhit__shadow_glass(

)
{



	ret;
}

	// .globl	__closesthit__shadow_glass
.visible .entry __closesthit__shadow_glass(

)
{
	.local .align 4 .b8 	__local_depot16[12];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<43>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<23>;


	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd3, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd5, %r1;
	shl.b64 	%rd6, %rd5, 32;
	cvt.u64.u32	%rd7, %r2;
	or.b64  	%rd8, %rd6, %rd7;
	// inline asm
	call (%rd1), _optix_get_sbt_data_ptr_64, ();
	// inline asm
	// inline asm
	call (%r3), _optix_read_primitive_idx, ();
	// inline asm
	ld.u64 	%rd9, [%rd1];
	mul.wide.s32 	%rd10, %r3, 12;
	add.s64 	%rd11, %rd9, %rd10;
	ld.u32 	%r13, [%rd11];
	ld.u32 	%r14, [%rd11+4];
	ld.u32 	%r15, [%rd11+8];
	// inline asm
	call (%f1, %f2), _optix_get_triangle_barycentrics, ();
	// inline asm
	mov.f32 	%f12, 0f3F800000;
	sub.ftz.f32 	%f13, %f12, %f1;
	sub.ftz.f32 	%f14, %f13, %f2;
	ld.u64 	%rd12, [%rd1+8];
	mul.wide.u32 	%rd13, %r13, 16;
	add.s64 	%rd14, %rd12, %rd13;
	ld.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd14];
	mov.u32 	%r7, 0;
	mov.u32 	%r10, 1;
	mov.u32 	%r9, 2;
	mul.wide.u32 	%rd15, %r14, 16;
	add.s64 	%rd16, %rd12, %rd15;
	ld.v4.f32 	{%f22, %f23, %f24, %f25}, [%rd16];
	mul.ftz.f32 	%f29, %f1, %f22;
	mul.ftz.f32 	%f30, %f1, %f23;
	mul.ftz.f32 	%f31, %f1, %f24;
	fma.rn.ftz.f32 	%f32, %f15, %f14, %f29;
	fma.rn.ftz.f32 	%f33, %f16, %f14, %f30;
	fma.rn.ftz.f32 	%f34, %f14, %f17, %f31;
	mul.wide.u32 	%rd17, %r15, 16;
	add.s64 	%rd18, %rd12, %rd17;
	ld.v4.f32 	{%f35, %f36, %f37, %f38}, [%rd18];
	fma.rn.ftz.f32 	%f3, %f2, %f35, %f32;
	fma.rn.ftz.f32 	%f4, %f2, %f36, %f33;
	fma.rn.ftz.f32 	%f5, %f2, %f37, %f34;
	mov.u64 	%rd19, 0;
	st.local.u32 	[%rd4+4], %rd19;
	st.local.u32 	[%rd4], %rd19;
	st.local.u32 	[%rd4+8], %r7;
	shr.u64 	%rd20, %rd3, 32;
	cvt.u32.u64	%r11, %rd20;
	cvt.u32.u64	%r12, %rd3;
	ld.const.u64 	%rd2, [optixLaunchParams+72];
	mov.u32 	%r6, 255;
	mov.f32 	%f6, 0fBF19999A;
	mov.f32 	%f7, 0f3ECCCCCD;
	mov.f32 	%f8, 0fBF333333;
	mov.f32 	%f9, 0f3727C5AC;
	mov.f32 	%f10, 0f60AD78EC;
	mov.f32 	%f11, 0f00000000;
	// inline asm
	call (%r4, %r5), _optix_trace_2, (%rd2, %f3, %f4, %f5, %f6, %f7, %f8, %f9, %f10, %f11, %r6, %r7, %r10, %r9, %r10, %r11, %r12);
	// inline asm
	ld.local.u32 	%rd21, [%rd4];
	ld.local.f32 	%f42, [%rd4+8];
	ld.local.u32 	%rd22, [%rd4+4];
	st.u32 	[%rd8+4], %rd22;
	st.u32 	[%rd8], %rd21;
	st.f32 	[%rd8+8], %f42;
	ret;
}

	// .globl	__miss__shadow_glass
.visible .entry __miss__shadow_glass(

)
{
	.reg .b32 	%r<4>;
	.reg .b64 	%rd<7>;


	// inline asm
	call (%r1), _optix_get_payload_0, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_payload_1, ();
	// inline asm
	cvt.u64.u32	%rd1, %r1;
	shl.b64 	%rd2, %rd1, 32;
	cvt.u64.u32	%rd3, %r2;
	or.b64  	%rd4, %rd2, %rd3;
	mov.u64 	%rd5, 0;
	st.u32 	[%rd4+4], %rd5;
	mov.u64 	%rd6, 1065353216;
	st.u32 	[%rd4], %rd6;
	mov.u32 	%r3, 0;
	st.u32 	[%rd4+8], %r3;
	ret;
}

	// .globl	__raygen__renderFrame
.visible .entry __raygen__renderFrame(

)
{
	.local .align 4 .b8 	__local_depot18[12];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<57>;
	.reg .b32 	%r<26>;
	.reg .b64 	%rd<10>;


	mov.u64 	%SPL, __local_depot18;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd2, %SP, 0;
	add.u64 	%rd3, %SPL, 0;
	// inline asm
	call (%r1), _optix_get_launch_index_x, ();
	// inline asm
	// inline asm
	call (%r2), _optix_get_launch_index_y, ();
	// inline asm
	mov.u64 	%rd4, 1065353216;
	st.local.u32 	[%rd3+4], %rd4;
	st.local.u32 	[%rd3], %rd4;
	mov.u32 	%r16, 1065353216;
	st.local.u32 	[%rd3+8], %r16;
	shr.u64 	%rd5, %rd2, 32;
	cvt.u32.u64	%r14, %rd5;
	cvt.u32.u64	%r15, %rd2;
	cvt.rn.f32.s32	%f10, %r1;
	add.ftz.f32 	%f11, %f10, 0f3F000000;
	cvt.rn.f32.s32	%f12, %r2;
	add.ftz.f32 	%f13, %f12, 0f3F000000;
	// inline asm
	call (%r4), _optix_get_launch_dimension_x, ();
	// inline asm
	// inline asm
	call (%r5), _optix_get_launch_dimension_y, ();
	// inline asm
	cvt.rn.f32.u32	%f14, %r4;
	cvt.rn.f32.u32	%f15, %r5;
	div.approx.ftz.f32 	%f16, %f11, %f14;
	div.approx.ftz.f32 	%f17, %f13, %f15;
	fma.rn.ftz.f32 	%f18, %f16, 0f40000000, 0fBF800000;
	fma.rn.ftz.f32 	%f19, %f17, 0f40000000, 0fBF800000;
	ld.const.v2.f32 	{%f20, %f21}, [optixLaunchParams+48];
	mov.u32 	%r13, 0;
	ld.const.v2.f32 	{%f24, %f25}, [optixLaunchParams+56];
	ld.const.v2.f32 	{%f28, %f29}, [optixLaunchParams+32];
	fma.rn.ftz.f32 	%f31, %f20, %f18, %f29;
	ld.const.v2.f32 	{%f32, %f33}, [optixLaunchParams+40];
	fma.rn.ftz.f32 	%f36, %f18, %f21, %f32;
	fma.rn.ftz.f32 	%f37, %f18, %f24, %f33;
	ld.const.v2.f32 	{%f38, %f39}, [optixLaunchParams+64];
	fma.rn.ftz.f32 	%f42, %f19, %f25, %f31;
	fma.rn.ftz.f32 	%f43, %f19, %f38, %f36;
	fma.rn.ftz.f32 	%f44, %f19, %f39, %f37;
	mul.ftz.f32 	%f45, %f43, %f43;
	fma.rn.ftz.f32 	%f46, %f42, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f44, %f44, %f46;
	rsqrt.approx.ftz.f32 	%f48, %f47;
	mul.ftz.f32 	%f4, %f42, %f48;
	mul.ftz.f32 	%f5, %f43, %f48;
	mul.ftz.f32 	%f6, %f44, %f48;
	ld.const.u64 	%rd1, [optixLaunchParams+72];
	ld.const.v2.f32 	{%f49, %f50}, [optixLaunchParams+24];
	mov.u32 	%r9, 255;
	mov.u32 	%r12, 2;
	mov.f32 	%f8, 0f60AD78EC;
	mov.f32 	%f9, 0f00000000;
	// inline asm
	call (%r7, %r8), _optix_trace_2, (%rd1, %f49, %f50, %f28, %f4, %f5, %f6, %f9, %f8, %f9, %r9, %r13, %r13, %r12, %r13, %r14, %r15);
	// inline asm
	ld.local.f32 	%f51, [%rd3];
	mul.ftz.f32 	%f52, %f51, 0f437F0000;
	cvt.rzi.ftz.s32.f32	%r17, %f52;
	ld.local.f32 	%f53, [%rd3+4];
	mul.ftz.f32 	%f54, %f53, 0f437F0000;
	cvt.rzi.ftz.s32.f32	%r18, %f54;
	ld.local.f32 	%f55, [%rd3+8];
	mul.ftz.f32 	%f56, %f55, 0f437F0000;
	cvt.rzi.ftz.s32.f32	%r19, %f56;
	shl.b32 	%r20, %r18, 8;
	shl.b32 	%r21, %r19, 16;
	or.b32  	%r22, %r17, %r20;
	or.b32  	%r23, %r22, %r21;
	or.b32  	%r24, %r23, -16777216;
	mad.lo.s32 	%r25, %r4, %r2, %r1;
	ld.const.u64 	%rd6, [optixLaunchParams+8];
	cvta.to.global.u64 	%rd7, %rd6;
	mul.wide.u32 	%rd8, %r25, 4;
	add.s64 	%rd9, %rd7, %rd8;
	st.global.u32 	[%rd9], %r24;
	ret;
}


