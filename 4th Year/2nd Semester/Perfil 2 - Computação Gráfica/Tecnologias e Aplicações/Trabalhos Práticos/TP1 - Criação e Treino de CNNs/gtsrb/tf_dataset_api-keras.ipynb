{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "https://www.youtube.com/watch?v=yH1cF7GnoIo    \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/tensorflow-tutorial    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "\n",
    "Batch size is an important parameter when training a network. It can influence speed and generalization, not necessarily in the same direction. There is no golden rule for the batch size but 32 is a commom number to start with.\n",
    "\n",
    "See: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
    "\n",
    "Try with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00000', '00001', '00002', '00003', '00004', '00005', '00006',\n",
       "       '00007', '00008', '00009', '00010', '00011', '00012', '00013',\n",
       "       '00014', '00015', '00016', '00017', '00018', '00019', '00020',\n",
       "       '00021', '00022', '00023', '00024', '00025', '00026', '00027',\n",
       "       '00028', '00029', '00030', '00031', '00032', '00033', '00034',\n",
       "       '00035', '00036', '00037', '00038', '00039', '00040', '00041',\n",
       "       '00042'], dtype='<U5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('gtsrb/train_images/')\n",
    "signs = list(data_dir.glob('00001/*'))\n",
    "\n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images takes place in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"gtsrb/train_images/*/*.png\")\n",
    "dataset = listset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about image shape and size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in dataset.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  \n",
    "dataset_length = [i for i,_ in enumerate(dataset)][-1] + 1\n",
    "print(\"Total images in dataset: \",dataset_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(buffer_size = dataset_length)\n",
    "dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "dataset = dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = tf.data.Dataset.list_files(\"gtsrb/test_images/*/*.png\")\n",
    "testset = testset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a batch of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(rows, columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    "        \n",
    "        \n",
    "image_batch, label_batch = next(iter(dataset))        \n",
    "show_batch(image_batch, label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def cnn55D3L2FC(classCount, imgSize, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='same',\n",
    "                     input_shape=(imgSize, imgSize, channels),\n",
    "                     activation='relu'))                     \n",
    "    model.add(Conv2D(64, (5, 5), activation='relu') ) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu') )   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(classCount, activation='softmax'))\n",
    "\n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ metrics.categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "model = cnn55D3L2FC(43, 32, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a diagram of the network\n",
    "\n",
    "This requires installing some packages, namely graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a table with model information\n",
    "\n",
    "When building a model kee an eye on the number of trainable parameters. Try to keep it below 10 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a random split to create a validation set\n",
    "\n",
    "Note that due to the way the GTSRB is build (using video sequences) this is not an ideal approach. Try to partition the set manually, selecting a few sequences for validation purposes. Load the training and validation sets independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * dataset_length)\n",
    "val_size = int(0.2 * dataset_length)\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(dataset, steps_per_epoch = 0.8*dataset_length/BATCH_SIZE,\n",
    "          epochs=20, validation_data = val_dataset, validation_steps= 0.2*dataset_length/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "\n",
    "This is the accuracy number that really matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
